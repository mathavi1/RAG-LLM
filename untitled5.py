# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nSTA5q_2vHz4lW6w3xdz7PZt1ZtNoDxb
"""

# RAG System with Groq LLM and Gradio Interface
# Install required packages first:
!pip install groq langchain langchain-community chromadb gradio pypdf python-docx openpyxl sentence-transformers

import gradio as gr
from groq import Groq
import os
from typing import List, Tuple
import tempfile
from pathlib import Path

# Document processing
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain_community.embeddings import HuggingFaceEmbeddings

# Document loaders
from langchain_community.document_loaders import (
    PyPDFLoader,
    TextLoader,
    Docx2txtLoader,
    UnstructuredExcelLoader
)

class RAGSystem:
    def __init__(self):
        self.client = None
        self.vectorstore = None
        self.embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )
        self.text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200,
            length_function=len
        )

    def verify_api_key(self, api_key: str) -> Tuple[str, str]:
        """Verify if the Groq API key is valid"""
        try:
            client = Groq(api_key=api_key)
            # Test with a simple completion
            response = client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": "Hi"}],
                max_tokens=10
            )
            self.client = client
            return "‚úÖ API Key is valid and working!", "success"
        except Exception as e:
            self.client = None
            return f"‚ùå API Key verification failed: {str(e)}", "error"

    def load_document(self, file_path: str) -> List:
        """Load document based on file type"""
        file_ext = Path(file_path).suffix.lower()

        try:
            if file_ext == '.pdf':
                loader = PyPDFLoader(file_path)
            elif file_ext == '.txt':
                loader = TextLoader(file_path)
            elif file_ext == '.docx':
                loader = Docx2txtLoader(file_path)
            elif file_ext in ['.xlsx', '.xls']:
                loader = UnstructuredExcelLoader(file_path)
            else:
                raise ValueError(f"Unsupported file type: {file_ext}")

            documents = loader.load()
            return documents
        except Exception as e:
            raise Exception(f"Error loading document: {str(e)}")

    def process_documents(self, files) -> str:
        """Process uploaded documents and create vector store"""
        if not files:
            return "‚ùå Please upload at least one document"

        try:
            all_documents = []

            for file in files:
                # Save uploaded file temporarily
                with tempfile.NamedTemporaryFile(delete=False, suffix=Path(file.name).suffix) as tmp:
                    tmp.write(file.read() if hasattr(file, 'read') else open(file, 'rb').read())
                    tmp_path = tmp.name

                # Load document
                docs = self.load_document(tmp_path)
                all_documents.extend(docs)

                # Clean up temp file
                os.unlink(tmp_path)

            # Split documents into chunks
            splits = self.text_splitter.split_documents(all_documents)

            # Create vector store
            self.vectorstore = Chroma.from_documents(
                documents=splits,
                embedding=self.embeddings,
                persist_directory="./chroma_db"
            )

            return f"‚úÖ Successfully processed {len(files)} document(s) with {len(splits)} chunks!"

        except Exception as e:
            return f"‚ùå Error processing documents: {str(e)}"

    def query_documents(self, question: str, chat_history: List) -> Tuple[str, List]:
        """Query the documents using RAG"""
        if not self.client:
            return "‚ùå Please verify your API key first", chat_history

        if not self.vectorstore:
            return "‚ùå Please upload and process documents first", chat_history

        if not question.strip():
            return "‚ùå Please enter a question", chat_history

        try:
            # Retrieve relevant documents
            relevant_docs = self.vectorstore.similarity_search(question, k=4)

            # Create context from relevant documents
            context = "\n\n".join([doc.page_content for doc in relevant_docs])

            # Create prompt
            prompt = f"""Based on the following context, please answer the question. If the answer is not in the context, say "I cannot find this information in the provided documents."

Context:
{context}

Question: {question}

Answer:"""

            # Get response from Groq
            response = self.client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1024
            )

            answer = response.choices[0].message.content

            # Update chat history
            chat_history.append((question, answer))

            return "", chat_history

        except Exception as e:
            return f"‚ùå Error: {str(e)}", chat_history

# Initialize RAG system
rag = RAGSystem()

# Create Gradio interface
with gr.Blocks(title="RAG System with Groq", theme=gr.themes.Soft()) as demo:
    gr.Markdown("# üìö RAG System with Groq LLM")
    gr.Markdown("Upload documents (PDF, TXT, DOCX, Excel) and ask questions!")

    with gr.Row():
        with gr.Column(scale=2):
            api_key_input = gr.Textbox(
                label="Groq API Key",
                placeholder="Enter your Groq API key...",
                type="password"
            )
        with gr.Column(scale=1):
            verify_btn = gr.Button("üîë Verify API Key", variant="primary")

    api_status = gr.Textbox(label="API Status", interactive=False)

    gr.Markdown("---")

    with gr.Row():
        file_upload = gr.File(
            label="üìÅ Upload Documents",
            file_count="multiple",
            file_types=[".pdf", ".txt", ".docx", ".xlsx", ".xls"]
        )

    process_btn = gr.Button("üì§ Process Documents", variant="primary")
    process_status = gr.Textbox(label="Processing Status", interactive=False)

    gr.Markdown("---")
    gr.Markdown("### üí¨ Ask Questions")

    chatbot = gr.Chatbot(label="Conversation", height=400)

    with gr.Row():
        question_input = gr.Textbox(
            label="Your Question",
            placeholder="Ask a question about your documents...",
            scale=4
        )
        submit_btn = gr.Button("Send", variant="primary", scale=1)

    error_output = gr.Textbox(label="Error Messages", visible=False)

    # Event handlers
    def verify_key(api_key):
        msg, status = rag.verify_api_key(api_key)
        return msg

    def process_files(files):
        return rag.process_documents(files)

    def submit_question(question, history):
        return rag.query_documents(question, history)

    verify_btn.click(
        fn=verify_key,
        inputs=[api_key_input],
        outputs=[api_status]
    )

    process_btn.click(
        fn=process_files,
        inputs=[file_upload],
        outputs=[process_status]
    )

    submit_btn.click(
        fn=submit_question,
        inputs=[question_input, chatbot],
        outputs=[question_input, chatbot]
    )

    question_input.submit(
        fn=submit_question,
        inputs=[question_input, chatbot],
        outputs=[question_input, chatbot]
    )

# Launch the app
if __name__ == "__main__":
    demo.launch(share=True, debug=True)

